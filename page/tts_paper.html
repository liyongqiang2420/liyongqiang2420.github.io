<!DOCTYPE html>
<html>
    <head>
        <title>TTS Paper</title>
        <style>
            a{ text-decoration:none;}
        </style>
    </head>
    <body>
        <input type="button" name="back" style="width:200px; height:150px; font-size:85px;" value="返回上一页" onclick="javascript:history.back(-1);"/>
        <h1>TTS Paper List</h1>
        <h2> A: Adaptation B: BackEnd F: FrontEnd M: Multilingual Speech Synthesis O: Other  </h2>
        <h2> 2020 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">2020</a></td>
                <td width="50" align="center">icassp</td>
                <td width="800">icassp 2020 speech synthesis session</td>
                <td width="200"><a href="https://2020.ieeeicassp-virtual.org/session/machine-learning-speech-synthesis-i">session1</a>
                &nbsp&nbsp<a href="https://2020.ieeeicassp-virtual.org/session/speech-synthesis-and-voice-conversion-i">session2</a>
                &nbsp&nbsp<a href="https://2020.ieeeicassp-virtual.org/session/speech-synthesis-and-voice-conversion-ii">session3</a></td>
            </tr> 
            <tr>
                <td width="50" align="center">ccf~</a></td>
                <td width="50" align="center">B</td>
                <td width="800">ccf语音对话与听觉前沿研讨会</td>
                <td width="200"><a href="https://www.bilibili.com/video/BV1MV411k7iJ?from=search&seid=10382597287268936144">vedio</a></td>
            </tr>
            <tr>
                <td width="50" align="center">speech synthesis</a></td>
                <td width="50" align="center">B</td>
                <td width="800">李宏毅</td>
                <td width="200"><a href="https://www.youtube.com/watch?v=DMxKeHW8KdM&feature=youtu.be">vedio</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2017~</a></td>
                <td width="50" align="center">B</td>
                <td width="800">tacotron</td>
                <td width="200"><a href="https://google.github.io/tacotron/index.html">paper</a></td>
            </tr>
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">INTERACTIVE TEXT-TO-SPEECH VIA SEMI-SUPERVISED STYLE TRANSFER LEARNING</td>
                <td width="200"><a href="../tts_paper/INTERACTIVE TEXT-TO-SPEECH VIA SEMI-SUPERVISED STYLE TRANSFER LEARNING.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2</td>
                <td width="50" align="center">B</td>
                <td width="800">SQUEEZEWAVE EXTREMELY LIGHTWEIGHT VOCODERS FOR ON DEVICE SPEECH SYNTHESIS</td>
                <td width="200"><a href="../tts_paper/SQUEEZEWAVE EXTREMELY LIGHTWEIGHT VOCODERS FOR ON DEVICE SPEECH SYNTHESIS.pdf">pdf</a>
                &nbsp&nbsp<a href="https://tianrengao.github.io/SqueezeWaveDemo/">demo</a>
                &nbsp&nbsp<a href="https://github.com/tianrengao/SqueezeWave">code</a></td>
            </tr>
            <tr>
                <td width="50" align="center">3</a></td>
                <td width="50" align="center">B</td>
                <td width="800">LOCATION RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG FORM SPEECH SYNTHESIS</td>
                <td width="200"><a href="../tts_paper/LOCATION RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG FORM SPEECH SYNTHESIS.pdf">pdf</a></td>
            </tr>
           <tr>
                <td width="50" align="center">4</td>
                <td width="50" align="center">B</td>
                <td width="800">End to End Adversarial Text to Speech</td>
                <td width="200"><a href="../tts_paper/End to End Adversarial Text to Speech.pdf">pdf</a>
                &nbsp&nbsp<a href="https://deepmind.com/research/publications/End-to-End-Adversarial-Text-to-Speech">demo</a>
            </tr>
        </table>
        <h2> 2019 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">2019</td>
                <td width="50" align="center">isca</td>
                <td width="800"> isca 2019 speech </td>
                <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2019/">papers</a></td>
            </tr>
            <tr>
                <td width="50" align="center">1</td>
                <td width="50" align="center">B</td>
                <td width="800">High quality, lightweight and adaptable TTS using LPCNet</td>
                <td width="200"><a href="../tts_paper/high_quality_lightweight_and_adaptable_tts_using_lpcnet.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2</td>
                <td width="50" align="center">B</td>
                <td width="800">Deep Text-to-Speech System with Seq2Seq Model</td>
                <td width="200"><a href="../tts_paper/Deep_Text-to-Speech_System_with_Seq2Seq_Model.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">3</td>
                <td width="50" align="center">B</td>
                <td width="800">FastSpeech: Fast, Robust and Controllable Text to Speech</td>
                <td width="200"><a href="../tts_paper/FastSpeech_Fast_Robust_and_Controllable_Text_to_Speech.pdf">pdf</a></td>
            </tr>
             <tr>
                <td width="50" align="center">4</td>
                <td width="50" align="center">B</td>
                <td width="800">A Neural Vocoder with Hierarchical Generation of Amplitude and Phase Spectra for Statistical Parametric Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/A_Neural_Vocoder_with_Hierarchical_Generation.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">5</td>
                <td width="50" align="center">B</td>
                <td width="800">Neural Speech Synthesis with Transformer Network</td>
                <td width="200"><a href="../tts_paper/Neural_Speech_Synthesis_with_Transformer_Network.pdf">pdf</a>
                &nbsp&nbsp<a href="../tts_paper/tts transformer .pptx">ppt</a>
                &nbsp&nbsp<a href="https://neuraltts.github.io/transformertts/">demo</a></td>
            </tr>
            <tr>
                <td width="50" align="center">6</td>
                <td width="50" align="center">B</td>
                <td width="800">Parallel Neural Text-to-Speech</td>
                <td width="200"><a href="../tts_paper/Parallel Neural Text-to-Speech.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">7</td>
                <td width="50" align="center">B</td>
                <td width="800">RawNet: Fast End-to-End Neural Vocoder</td>
                <td width="200"><a href="../tts_paper/RawNet Fast End-to-End Neural Vocoder.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">8</td>
                <td width="50" align="center">B</td>
                <td width="800">Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS</td>
                <td width="200"><a href="../tts_paper/Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">9</td>
                <td width="50" align="center">O</td>
                <td width="800">LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech</td>
                <td width="200"><a href="../tts_paper/libriTTS.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">10</td>
                <td width="50" align="center">B</td>
                <td width="800">A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet</td>
                <td width="200"><a href="../tts_paper/A Real-Time Wideband Neural Vocoder at 1.6 kbs Using LPCNet.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">11</td>
                <td width="50" align="center">B</td>
                <td width="800">Lpcnet improving neural speech synthesis through linear prediction</td>
                <td width="200"><a href="../tts_paper/LPCNET: IMPROVING NEURAL SPEECH SYNTHESIS THROUGH LINEAR PREDICTION.pdf">pdf</a>
                &nbsp&nbsp<a href="https://people.xiph.org/~jm/demo/lpcnet/">demo</a>
                &nbsp&nbsp<a href="https://github.com/drowe67/LPCNet">code</a></td>
            </tr>
            <tr>
                <td width="50" align="center">12</td>
                <td width="50" align="center">B</td>
                <td width="800">Forward-Backward Decoding for Regularizing End-to-End TTS</td>
                <td width="200"><a href="../tts_paper/Forward-Backward Decoding for Regularizing End-to-End TTS.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">13</td>
                <td width="50" align="center">O</td>
                <td width="800">(talking head) Text-based Editing of Talking-head Video</td>
                <td width="200"><a href="../tts_paper/Text-based Editing of Talking-head Video.pdf">pdf</a>
                &nbsp&nbsp<a href="https://www.ohadf.com/projects/text-based-editing/">vedio</a></td>
            </tr>
            <tr>
                <td width="50" align="center">14</td>
                <td width="50" align="center">F</td>
                <td width="800">Self-attention Based Prosodic Boundary Prediction for Chinese Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Self-attention Based Prosodic Boundary Prediction for Chinese Speech Synthesis.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">15</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Guide to Speech Synthesis with Deep Learning</td>
                <td width="200"><a href="../tts_paper/Guide to Speech Synthesis with Deep Learning.pdf">ppt</a></td>
            </tr>
            <tr>
                <td width="50" align="center">16</a></td>
                <td width="50" align="center">B</td>
                <td width="800">tts tutorial part1 part2</td>
                <td width="200"><a href="../tts_paper/tts tutorial part1.pdf">ppt1</a>
                &nbsp&nbsp<a href="../tts_paper/tts_tutorial part2.pdf">ppt2</a></td>
            </tr>
            <tr>
                <td width="50" align="center">17</a></td>
                <td width="50" align="center">M</td>
                <td width="800">learning to speak fluently in a foreign language multilingual speech synthesis and cross language voice cloning</td>
                <td width="200"><a href="../tts_paper/learning to speak fluently in a foreign language multilingual speech synthesis and cross language voice cloning.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">18</a></td>
                <td width="50" align="center">B</td>
                <td width="800">maximizing mutual infotmation for tacotron</td>
                <td width="200"><a href="../tts_paper/MAXIMIZING MUTUAL INFORMATION FOR TACOTRON.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">19</a></td>
                <td width="50" align="center">F</td>
                <td width="800">Token Level Ensemble Distillation for Grapheme to Phoneme Conversion</td>
                <td width="200"><a href="../tts_paper/Token Level Ensemble Distillation for Grapheme to Phoneme Conversion.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">20</a></td>
                <td width="50" align="center">F</td>
                <td width="800">DURIAN: DURATION INFORMED ATTENTION NETWORK FOR MULTIMODAL SYNTHESIS</td>
                <td width="200"><a href="../tts_paper/DURIAN: DURATION INFORMED ATTENTION NETWORK FOR MULTIMODAL SYNTHESIS.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">21</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Cross lingual Multispeaker Text To Speech Synthesis Using Neural Speaker Embedding</td>
                <td width="200"><a href="../tts_paper/Cross lingual Multispeaker Text To Speech Synthesis Using Neural Speaker Embedding.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">22</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Waveglow</td>
                <td width="200"><a href="../tts_paper/waveglow.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">23</td>
                <td width="50" align="center">O</td>
                <td width="800">Talking Face Generation by Adversarially Disentangled Audio-Visual Representation</td>
                <td width="200"><a href="../tts_paper/Talking Face Generation by Adversarially Disentangled Audio-Visual Representation.pdf">pdf</a>
                &nbsp&nbsp<a href="https://github.com/Hangz-nju-cuhk/Talking-Face-Generation-DAVS">code</a>
                &nbsp&nbsp<a href="https://www.youtube.com/watch?v=-J2zANwdjcQ">demo</a></td>
           </tr>
           <tr>
                <td width="50" align="center">24</td>
                <td width="50" align="center">B</td>
                <td width="800">Automatic Multispeaker Voice Cloning</td>
                <td width="200"><a href="../tts_paper/Automatic Multispeaker Voice Cloning.pdf">pdf</a>
                &nbsp&nbsp<a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning">code</a>
           </tr>
           <tr>
                <td width="50" align="center">25</td>
                <td width="50" align="center">B</td>
                <td width="800">Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis.pdf">pdf</a>
                &nbsp&nbsp<a href="https://google.github.io/tacotron/publications/speaker_adaptation/">demo</a></td>
           </tr>
           <tr>
                <td width="50" align="center">26</td>
                <td width="50" align="center">B</td>
                <td width="800">Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis.pdf">pdf</a>
                &nbsp&nbsp<a href="https://google.github.io/tacotron/publications/speaker_adaptation/">demo</a></td>
           </tr>
           <tr>
                <td width="50" align="center">27</td>
                <td width="50" align="center">B</td>
                <td width="800">High quality lightweight and adaptable TTS using LPCNet</td>
                <td width="200"><a href="../tts_paper/High quality lightweight and adaptable TTS using LPCNet.pdf">pdf</a>
           </tr>
        </table>
        <h2> 2018 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">2018</td>
                <td width="50" align="center">isca</td>
                <td width="800"> isca 2018 speech </td>
                <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2018/">papers</a></td>
            </tr>
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Natural TTS Synthesis by Conditioning Wavennet on MEL spectrogram predictions(tacotron2)</td>
                <td width="200"><a href="../tts_paper/Natural_TTS_Synthesis by_Conditioning_Wavennet_on_MEL_spectrogram_predictions.pdf">pdf</a>
                &nbsp&nbsp<a href="https://github.com/NVIDIA/tacotron2">code</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Deep voice 3: Scaling text-to-speech with convolutional sequence learning</td>
                <td width="200"><a href="../tts_paper/deep_voice3.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">3</a></td>
                <td width="50" align="center">B</td>
                <td width="800">ClariNet Parallel Wave Generation in End-to-End Text-to-Speech</td>
                <td width="200"><a href="../tts_paper/ClariNet Parallel Wave Generation in End-to-End Text-to-Speech.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">4</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Efficient Neural Audio Synthesis (WaveRNN)</td>
                <td width="200"><a href="../tts_paper/Efficient Neural Audio Synthesis.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">5</a></td>
                <td width="50" align="center">F</td>
                <td width="800">Mandarin Prosody Prediction Based on Attention Mechanism and Multi-model Ensemble</td>
                <td width="200"><a href="../tts_paper/Mandarin Prosody Prediction Based on Attention Mechanism and Multimodel Ensemble.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">6</a></td>
                <td width="50" align="center">A</td>
                <td width="800">Linear Networks Based Speaker Adaptation For Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Linear Networks Based Speaker Adaptation For Speech Synthesis.pdf">pdf</a></td>
            </tr>
        </table>    
        <h2> 2017 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">2017</td>
                <td width="50" align="center">isca</td>
                <td width="800"> isca 2017 speech </td>
                <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2017/">papers</a></td>
            </tr>
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Tacotron: Towards End-to-End Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/tacotron.pdf">pdf</a>
                &nbsp&nbsp<a href="https://google.github.io/tacotron/index.html">page</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Parallel WaveNet: Fast High-Fidelity Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Parallel_WaveNet-Fast_High-Fidelity_Speech_Synthesis.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">3</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Char2Wav: End-to-End Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Char2Wav-End-to-End_Speech_Synthesis.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">4</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Deep Voice: Real-time Neural Text-to-Speech</td>
                <td width="200"><a href="../tts_paper/Deep_Voice-Real-time_Neural_Text-to-Speech.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">5</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Deep Voice 2: Multi-Speaker Neural Text-to-Speech</td>
                <td width="200"><a href="../tts_paper/DeepVoice2-Multi-Speaker_Neural_Text-to-Speech.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">6</a></td>
                <td width="50" align="center">B</td>
                <td width="800">VoiceLoop voice fitting and synthesis via a phonological loop</td>
                <td width="200"><a href="../tts_paper/VOICELOOP- VOICE FITTING AND SYNTHESIS VIA A PHONOLOGICAL LOOP.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">7</a></td>
                <td width="50" align="center">O</td>
                <td width="800">Attention Is All You Need</td>
                <td width="200"><a href="../tts_paper/Attention Is All You Need.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">8</a></td>
                <td width="50" align="center">A</td>
                <td width="800">Speaker adaptation in DNN-based speech synthesis using d-vectors</td>
                <td width="200"><a href="../tts_paper/Speaker adaptation in DNNbased speech synthesis using dvectors.pdf">pdf</a></td>
            </tr>
        </table>
        <h2> 2016 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">2016</td>
                <td width="50" align="center">isca</td>
                <td width="800"> isca 2016 speech </td>
                <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2016/">papers</a></td>
            </tr>
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Wavenet A Generative Model For Raw Audio</td>
                <td width="200"><a href="../tts_paper/Wavenet_A_Generative_Model_For_Raw_Audio.pdf">pdf</a>&nbsp&nbsp
                                <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/ibab/tensorflow-wavenet">code</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Fast Wavenet Geneartion Algorithm</td>
                <td width="200"><a href="../tts_paper/Fast_Wavenet_Geneartion_Algorithm.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">3</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices</td>
                <td width="200"><a href="../tts_paper/Fast_Compact_and_High_Quality_LSTM-RNN_Based_Statistical_Parametric.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">4</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Merlin: An Open Source Neural Network Speech Synthesis System</td>
                <td width="200"><a href="../tts_paper/Merlin_An_Open_Source_Neural_Network_Speech_Synthesis_System.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">5</a></td>
                <td width="50" align="center">F</td>
                <td width="800">Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach</td>
                <td width="200"><a href="../tts_paper/Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">6</a></td>
                <td width="50" align="center">A</td>
                <td width="800">Speaker Representations for Speaker Adaptation in Multiple Speakers’BLSTM-RNN-based Speech Synthesis</td>
                <td width="200"><a href="../tts_paper/Speaker Representations for Speaker Adaptation in Multiple Speakers’BLSTM-RNN-based Speech Synthesis.pdf">pdf</a></td>
            </tr>
         </table>
        <h2> 2015 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Acoustic modeling instatistical parametric speechsynthesis-from HMM to LSTM-RNN</td>
                <td width="200"><a href="../tts_paper/Acoustic_modeling_instatistical_parametric_speechsynthesis-from_HMM_to_LSTM-RNN.pdf">pdf</a>
                    &nbsp&nbsp<a href="../tts_paper/Statistical Parametric Speech SynthesisFromHMMtoLSTMRNN_ppt.pdf">ppt</a></td>
            </tr>
            <tr>
                <td width="50" align="center">2</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Effective Approaches to Attention-based Neural Machine Translation</td>
                <td width="200"><a href="../tts_paper/Effective Approaches to Attention-based Neural Machine Translation.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">3</a></td>
                <td width="50" align="center">B</td>
                <td width="800">htkbook-3.5</td>
                <td width="200"><a href="../tts_paper/htkbook-3.5.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">4</a></td>
                <td width="50" align="center">F</td>
                <td width="800">AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES</td>
                <td width="200"><a href="../tts_paper/AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">5</a></td>
                <td width="50" align="center">A</td>
                <td width="800">A study of speaker adaptation for DNN-based speech synthesis</td>
                <td width="200"><a href="../tts_paper/A study of speaker adaptation for DNN-based speech synthesis.pdf">pdf</a></td>
            </tr>
            <tr>
                <td width="50" align="center">6</a></td>
                <td width="50" align="center">A</td>
                <td width="800">Multi-speaker modeling and speaker adaptation for dnn-based tts synthesis</td>
                <td width="200"><a href="../tts_paper/Multispeaker modeling and speaker adaptation for dnnbased tts synthesis.pdf">pdf</a></td>
            </tr>
         </table>
        <h2> 2014 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">TTS Synthesis with Bidirectional LSTM based Recurrent Neural Networks </td>
                <td width="200"><a href="../tts_paper/TTS_Synthesis_with_Bidirectional_LSTM_based_Recurrent_Neural_Networks.pdf">pdf</a></td>
            </tr>
        </table>
        <h2> 2013 </h2>
        <table width="1100" border="1">
            <tr>
                <td width="50" align="center">1</a></td>
                <td width="50" align="center">B</td>
                <td width="800">Statical parameteric speech synthesis Using deep neural networks </td>
                <td width="200"><a href="../tts_paper/Statical parameteric speech synthesis Using deep neural networks.pdf">pdf</a></td>
            </tr>
        </table>
    </body>
</html>
