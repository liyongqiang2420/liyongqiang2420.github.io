<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <!--头部信息-->
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <!--title keywords description 请改为自己的-->
    <title>低调奋进</title>

    <!--网站favicon可以没有或者改为自己的-->
    <!--<link rel="shortcut icon" type="image/x-icon" href="http://www.bituplink.com/wp-content/uploads/favicon.png"/>-->

    <!--CSS 若不需要变动样式不用改-->
    <link href="plugin/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/zui/1.8.1/css/zui.min.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" type="text/css" href="../css/common.css" />
    <link href="../img/logo.ico" rel="shortcut icon" />
    <script src="plugin/jquery.min.js"></script>
    <script src="plugin/bootstrap/js/bootstrap.min.js"></script>
</head>
<body id="nav_body">
<!--[if lt IE 10]>
<div class="alert alert-danger">
    您正在使用 
    <strong>过时的</strong> 浏览器. 请更换一个更好的浏览器来提升用户体验.
</div>
<![endif]--><!--头部导航条-->
<div id="content">
    <div class="w_header">
      <div class="container">
        <div class="w_header_top">
          <a href="../index.html" class="w_logo"></a>
          <span class="w_header_nav">
              <ul>
                <li><a href="../index.html">Home</a></li>
                <li><a href="speech.html" class="active">Speech & ML</a></li>
                <li><a href="pro.html">Programming</a></li>
                <li><a href="moodList.html">Life</a></li>
                <li><a href="tools.html">Tool</a></li>
                <li><a href="about.html">About</a></li>
            </ul>
        </span>
    </div>
</div>
</div>

<!--左侧Director，导航跳转-->
<div class="left-bar">
    <div class="header">
        <h2>Director</h2>
    </div>
    <div class="menu" id="menu">
        <ul class="scrollcontent">
            <!--左侧Director，按照需要修改和添加，参考已有的修改名称和href-->
            <li><a href="#row-1">General TTS</a></li>
            <li><a href="#row-2">Vocoder</a></li>
            <li><a href="#row-3">Multi spks & lingual</a></li>
            <li><a href="#row-4">Expressive TTS</a></li>
            <li><a href="#row-5">Voice Conversion</a></li>
            <li><a href="#row-6">Sing Synthesis</a></li>
            <li><a href="#row-7">Talking Head</a></li>
            <li><a href="#row-8">Robust TTS</a></li>
            <li><a href="#row-9">Front End</a></li>
            <li><a href="#row-10">Alignment</a></li>
            <li><a href="#row-11">Dual learning</a></li>
        </ul>
    </div>
</div>
<!--内容-->
<div class="main">
    <div class="container content-box">
        <!--导航分类范例1，请根据自己的需求进行修改-->
        <section class="item card-box" id="row-1">
            <div class="container-fluid">
                <div class="row">
                    <div class="item-tit">
                        <strong>Journal and conference on speech</strong>
                        <table width="1150" border="1">
                            <tr>
                                <td width="150" align="center">CCF-A</a></td>
                                <td width="1000">NeuraIPS  AAAI  IJAI  ACMMM </tr>
                            </tr>
                            <tr>
                                <td width="150" align="center">CCF-B</a></td>
                                <td width="1000">ICASSP  COLING  SpeechCom  TSLP  TASLP  JSLHR  TMM  TOMCCAP ICME </tr>
                            </tr>
                            <tr>
                                <td width="150" align="center">CCF-C</a></td>
                                <td width="1000">INTERSPEECH  ICPR </td>
                            </tr>
                        </table>
                    </div>
                    <div class="item-tit">
                        <strong>General TTS</strong>
                    </div>
                    <!--获取内容列表-->

                    <h3> 2020 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">INTERACTIVE TEXT-TO-SPEECH VIA SEMI-SUPERVISED STYLE TRANSFER LEARNING</td>
                            <td width="200"><a href="../pdf/tts_paper/INTERACTIVE TEXT-TO-SPEECH VIA SEMI-SUPERVISED STYLE TRANSFER LEARNING.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">SQUEEZEWAVE EXTREMELY LIGHTWEIGHT VOCODERS FOR ON DEVICE SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/SQUEEZEWAVE EXTREMELY LIGHTWEIGHT VOCODERS FOR ON DEVICE SPEECH SYNTHESIS.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://tianrengao.github.io/SqueezeWaveDemo/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/tianrengao/SqueezeWave">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">LOCATION RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG FORM SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/LOCATION RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG FORM SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">End to End Adversarial Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/End to End Adversarial Text to Speech.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://deepmind.com/research/publications/End-to-End-Adversarial-Text-to-Speech">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">FastSpeech 2 Fast and High Quality End to End Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/FastSpeech 2 Fast and High Quality End to End Text to Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Deep Representation Learning in Speech Processing Challenges Recent Advances and Future Trends</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep Representation Learning in Speech Processing Challenges Recent Advances and Future Trends.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Flowtron an Autoregressive Flowbased Generative Network for TexttoSpeech Synthesis.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/Flowtron an Autoregressive Flowbased Generative Network for TexttoSpeech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">JDI-T- Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment</td>
                            <td width="200"><a href="../pdf/tts_paper/JDI-T- Jointly trained Duration Informed Transformer for Text-To-Speech without Explicit Alignment.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">FastPitch- Parallel Text-to-speech with Pitch Prediction.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/FastPitch- Parallel Text-to-speech with Pitch Prediction.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Glow-TTS- A Generative Flow for Text-to-Speech via Monotonic Alignment Search.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/Glow-TTS- A Generative Flow for Text-to-Speech via Monotonic Alignment Search.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">FLOW-TTS: A NON-AUTOREGRESSIVE NETWORK FOR TEXT TO SPEECH BASED ON FLOW</td>
                            <td width="200"><a href="../pdf/tts_paper/FLOW-TTS: A NON-AUTOREGRESSIVE NETWORK FOR TEXT TO SPEECH BASED ON FLOW.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">SpeedySpeech- Efficient Neural Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/SpeedySpeech- Efficient Neural Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">End-to-End Adversarial Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/End-to-End Adversarial Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Controllable Neural Prosody Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Controllable Neural Prosody Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep MOS Predictor for Synthetic Speech Using Cluster-Based Modeling.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">Exploring TTS without T Using Biologically/Psychologically Motivated Neural Network Modules (ZeroSpeech 2020)</td>
                            <td width="200"><a href="../pdf/tts_paper/Exploring TTS without T Using Biologically/Psychologically Motivated Neural Network Modules (ZeroSpeech 2020).pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">17</a></td>
                            <td width="800">From Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint</td>
                            <td width="200"><a href="../pdf/tts_paper/From Speaker Verification to Multispeaker Speech Synthesis, Deep Transfer with Feedback Constraint.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">18</a></td>
                            <td width="800">Incremental Text to Speech for Neural Sequence-to-Sequence Models using Reinforcement Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/Incremental Text to Speech for Neural Sequence-to-Sequence Models using Reinforcement Learning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">19</a></td>
                            <td width="800">Prosody Learning Mechanism for Speech Synthesis System Without Text Length Limit</td>
                            <td width="200"><a href="../pdf/tts_paper/Prosody Learning Mechanism for Speech Synthesis System Without Text Length Limit.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">20</a></td>
                            <td width="800">Unsupervised Learning For Sequence-to-sequence Text-to-speech For Low-resource Languages</td>
                            <td width="200"><a href="../pdf/tts_paper/Unsupervised Learning For Sequence-to-sequence Text-to-speech For Low-resource Languages.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">21</a></td>
                            <td width="800">Speaking Speed Control of End-to-End Speech Synthesis using Sentence-Level Conditioning</td>
                            <td width="200"><a href="../pdf/tts_paper/Speaking Speed Control of End-to-End Speech Synthesis using Sentence-Level Conditioning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">22</a></td>
                            <td width="800">Recognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/Recognition-Synthesis Based Non-Parallel Voice Conversion with Adversarial Learning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">23</a></td>
                            <td width="800">NON-ATTENTIVE TACOTRON- ROBUST AND CONTROLLABLE NEURAL TTS SYNTHESIS INCLUDING UNSUPERVISED DURATION MODELING</td>
                            <td width="200"><a href="../pdf/tts_paper/NON-ATTENTIVE TACOTRON- ROBUST AND CONTROLLABLE NEURAL TTS SYNTHESIS INCLUDING UNSUPERVISED DURATION MODELING.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">24</a></td>
                            <td width="800">PARALLEL TACOTRON- NON-AUTOREGRESSIVE AND CONTROLLABLE TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/PARALLEL TACOTRON- NON-AUTOREGRESSIVE AND CONTROLLABLE TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">25</a></td>
                            <td width="800">TTS-BY-TTS- TTS-DRIVEN DATA AUGMENTATION FOR FAST AND HIGH-QUALITY SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/TTS-BY-TTS- TTS-DRIVEN DATA AUGMENTATION FOR FAST AND HIGH-QUALITY SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">26</a></td>
                            <td width="800">SPEECH SYNTHESIS AND CONTROL USING DIFFERENTIABLE DSP</td>
                            <td width="200"><a href="../pdf/tts_paper/SPEECH SYNTHESIS AND CONTROL USING DIFFERENTIABLE DSP.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">27</a></td>
                            <td width="800">FEATHERTTS- ROBUST AND EFFICIENT ATTENTION BASED NEURAL TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/FEATHERTTS- ROBUST AND EFFICIENT ATTENTION BASED NEURAL TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">28</a></td>
                            <td width="800">GRAPHSPEECH: SYNTAX-AWARE GRAPH ATTENTION NETWORK FOR NEURAL SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/GRAPHSPEECH- SYNTAX-AWARE GRAPH ATTENTION NETWORK FOR NEURAL SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">29</a></td>
                            <td width="800">HIERARCHICAL PROSODY MODELING FOR NON-AUTOREGRESSIVE SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/HIERARCHICAL PROSODY MODELING FOR NON-AUTOREGRESSIVE SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                            <td width="150" align="center">30</a></td>
                            <td width="800">DEVICETTS: A SMALL-FOOTPRINT, FAST, STABLE NETWORK FOR ON-DEVICE TEXT-TO-SPEECH</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2010.15311.pdf">pdf</a></td>
                        </tr>
                        </tr>
                            <td width="150" align="center">31</a></td>
                            <td width="800">PRETRAINING STRATEGIES, WAVEFORM MODEL CHOICE, AND ACOUSTIC CONFIGURATIONS FOR MULTI-SPEAKER END-TO-END SPEECH SYNTHESIS</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.04839.pdf">pdf</a></td>
                        </tr>
                        </tr>
                            <td width="150" align="center">32</a></td>
                            <td width="800">Fast and lightweight on-device TTS with Tacotron2 and LPCNet</td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2020/pdfs/2169.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2019 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">2019</td>
                            <td width="800"> isca 2019 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2019/">papers</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Deep Text-to-Speech System with Seq2Seq Model</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep_Text-to-Speech_System_with_Seq2Seq_Model.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">FastSpeech: Fast, Robust and Controllable Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/FastSpeech_Fast_Robust_and_Controllable_Text_to_Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">Neural Speech Synthesis with Transformer Network</td>
                            <td width="200"><a href="../pdf/tts_paper/Neural_Speech_Synthesis_with_Transformer_Network.pdf">pdf</a>
                                &nbsp&nbsp<a href="../pdf/tts_paper/tts transformer .pptx">ppt</a>
                                &nbsp&nbsp<a href="https://neuraltts.github.io/transformertts/">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">Parallel Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/Parallel Neural Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</td>
                            <td width="800">Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</td>
                            <td width="800">LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/libriTTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</td>
                            <td width="800">Forward-Backward Decoding for Regularizing End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Forward-Backward Decoding for Regularizing End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</td>
                            <td width="800">Self-attention Based Prosodic Boundary Prediction for Chinese Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Self-attention Based Prosodic Boundary Prediction for Chinese Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Guide to Speech Synthesis with Deep Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/Guide to Speech Synthesis with Deep Learning.pdf">ppt</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">tts tutorial part1 part2</td>
                            <td width="200"><a href="../pdf/tts_paper/tts tutorial part1.pdf">ppt1</a>
                                &nbsp&nbsp<a href="../pdf/tts_paper/tts_tutorial part2.pdf">ppt2</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">maximizing mutual information for tacotron</td>
                            <td width="200"><a href="../pdf/tts_paper/MAXIMIZING MUTUAL INFORMATION FOR TACOTRON.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</td>
                            <td width="800">durlan</td>
                            <td width="200"><a href="../pdf/tts_paper/DURIAN DURATION INFORMED ATTENTION NETWORK FOR MULTIMODAL SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</td>
                            <td width="800">Non-Autoregressive Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/Non-Autoregressive Neural Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Tacotron-based acoustic model using phoneme alignment for practical neural text-to-speech systems</td>
                            <td width="200"><a href="../pdf/tts_paper/Tacotron-based acoustic model using phoneme alignment for practical neural text-to-speech systems.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2018 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">2018</td>
                            <td width="800"> isca 2018 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2018/">papers</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Deep voice 3: Scaling text-to-speech with convolutional sequence learning</td>
                            <td width="200"><a href="../pdf/tts_paper/deep_voice3.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">ClariNet Parallel Wave Generation in End-to-End Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/ClariNet Parallel Wave Generation in End-to-End Text-to-Speech.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Linear Networks Based Speaker Adaptation For Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Linear Networks Based Speaker Adaptation For Speech Synthesis.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>    
                    <h3> 2017 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">2017</td>
                            <td width="800"> isca 2017 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2017/">papers</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Tacotron: Towards End-to-End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/tacotron.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://google.github.io/tacotron/index.html">page</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Char2Wav: End-to-End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Char2Wav-End-to-End_Speech_Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Deep Voice: Real-time Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep_Voice-Real-time_Neural_Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Deep Voice 2: Multi-Speaker Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/DeepVoice2-Multi-Speaker_Neural_Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">VoiceLoop voice fitting and synthesis via a phonological loop</td>
                            <td width="200"><a href="../pdf/tts_paper/VOICELOOP- VOICE FITTING AND SYNTHESIS VIA A PHONOLOGICAL LOOP.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Attention Is All You Need</td>
                            <td width="200"><a href="../pdf/tts_paper/Attention Is All You Need.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2016 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">2016</td>
                            <td width="800"> isca 2016 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2016/">papers</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices</td>
                            <td width="200"><a href="../pdf/tts_paper/Fast_Compact_and_High_Quality_LSTM-RNN_Based_Statistical_Parametric.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Merlin: An Open Source Neural Network Speech Synthesis System</td>
                            <td width="200"><a href="../pdf/tts_paper/Merlin_An_Open_Source_Neural_Network_Speech_Synthesis_System.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2015 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Acoustic modeling instatistical parametric speechsynthesis-from HMM to LSTM-RNN</td>
                            <td width="200"><a href="../pdf/tts_paper/Acoustic_modeling_instatistical_parametric_speechsynthesis-from_HMM_to_LSTM-RNN.pdf">pdf</a>
                                &nbsp&nbsp<a href="../pdf/tts_paper/Statistical Parametric Speech SynthesisFromHMMtoLSTMRNN_ppt.pdf">ppt</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Effective Approaches to Attention-based Neural Machine Translation</td>
                            <td width="200"><a href="../pdf/tts_paper/Effective Approaches to Attention-based Neural Machine Translation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">htkbook-3.5</td>
                            <td width="200"><a href="../pdf/tts_paper/htkbook-3.5.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">A study of speaker adaptation for DNN-based speech synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/A study of speaker adaptation for DNN-based speech synthesis.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2014 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">TTS Synthesis with Bidirectional LSTM based Recurrent Neural Networks </td>
                            <td width="200"><a href="../pdf/tts_paper/TTS_Synthesis_with_Bidirectional_LSTM_based_Recurrent_Neural_Networks.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>
                    <h3> 2013 </h3>
                    <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Statical parameteric speech synthesis Using deep neural networks </td>
                            <td width="200"><a href="../pdf/tts_paper/Statical parameteric speech synthesis Using deep neural networks.pdf">pdf</a></td>
                        </tr>
                    </table>
                </div>
            </div>
        </section>
<section class="item card-box" id="row-2">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Vocoder</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">multiband melgan</td>
                            <td width="200"><a href="../pdf/tts_paper/multiband melgan.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">FeatherWave An efficient high fidelity neural vocoder with multiband linear prediction</td>
                            <td width="200"><a href="../pdf/tts_paper/FeatherWave An efficient high fidelity neural vocoder with multiband linear prediction.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">parallel wavegan</td>
                            <td width="200"><a href="../pdf/tts_paper/parallel wavegan.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">VocGan</td>
                            <td width="200"><a href="../pdf/tts_paper/VocGAN- A High-Fidelity Real-time Vocoder with a Hierarchically nested Adversarial Network.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">WAVEGRAD- ESTIMATING GRADIENTS FOR WAVEFORM GENERATION</td>
                            <td width="200"><a href="../pdf/tts_paper/WAVEGRAD- ESTIMATING GRADIENTS FOR WAVEFORM GENERATION.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">PARALLEL WAVEGAN- A FAST WAVEFORM GENERATION MODEL BASED ON GENERATIVE ADVERSARIAL NETWORKS WITH MULTI-RESOLUTION SPECTROGRAM</td>
                            <td width="200"><a href="../pdf/tts_paper/PARALLEL WAVEGAN- A FAST WAVEFORM GENERATION MODEL BASED ON GENERATIVE ADVERSARIAL NETWORKS WITH MULTI-RESOLUTION SPECTROGRAM.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">WAVEGRAD  ESTIMATING GRADIENTS FOR WAVEFORM GENERATION</td>
                            <td width="200"><a href="../pdf/tts_paper/WAVEGRAD  ESTIMATING GRADIENTS FOR WAVEFORM GENERATION.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">A Cyclical Post-filtering Approach to Mismatch Refinement of Neural Vocoder for Text-to-speech Systems</td>
                            <td width="200"><a href="../pdf/tts_paper/A Cyclical Post-filtering Approach to Mismatch Refinement of Neural Vocoder for Text-to-speech Systems.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Bunched LPCNet - Vocoder for Low-cost Neural Text-To-Speech Systems</td>
                            <td width="200"><a href="../pdf/tts_paper/Bunched LPCNet - Vocoder for Low-cost Neural Text-To-Speech Systems.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Quasi-Periodic Parallel WaveGAN Vocoder- A Non-autoregressive Pitchdependent Dilated Convolution Model for Parametric Speech Generation</td>
                            <td width="200"><a href="../pdf/tts_paper/Quasi-Periodic Parallel WaveGAN Vocoder- A Non-autoregressive Pitchdependent Dilated Convolution Model for Parametric Speech Generation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">Neural Text-to-Speech with a Modeling-by-Generation Excitation Vocoder</td>
                            <td width="200"><a href="../pdf/tts_paper/Neural Text-to-Speech with a Modeling-by-Generation Excitation Vocoder.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">Improving Opus Low Bit Rate Quality with Neural Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Improving Opus Low Bit Rate Quality with Neural Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">WG-WaveNet- Real-Time High-Fidelity Speech Synthesis without GPU</td>
                            <td width="200"><a href="../pdf/tts_paper/WG-WaveNet- Real-Time High-Fidelity Speech Synthesis without GPU.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Vocoder-Based Speech Synthesis from Silent Videos</td>
                            <td width="200"><a href="../pdf/tts_paper/Vocoder-Based Speech Synthesis from Silent Videos.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Ultrasound-based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Ultrasound-based Articulatory-to-Acoustic Mapping with WaveGlow Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">Speaker Conditional WaveRNN- Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions</td>
                            <td width="200"><a href="../pdf/tts_paper/Speaker Conditional WaveRNN- Towards Universal Neural Vocoder for Unseen Speaker and Recording Conditions.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">17</a></td>
                            <td width="800">GAUSSIAN LPCNET FOR MULTISAMPLE SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/GAUSSIAN LPCNET FOR MULTISAMPLE SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">18</a></td>
                            <td width="800">UNIVERSAL MELGAN: A ROBUST NEURAL VOCODER FOR HIGH-FIDELITY WAVEFORM GENERATION IN MULTIPLE DOMAINS</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.09631.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">19</a></td>
                            <td width="800">Improving LPCNet-based Text-to-Speech with Linear Prediction-structured Mixture Density Network</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2001.11686.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">20</a></td>
                            <td width="800">What the Future Brings: Investigating the Impact of Lookahead for Incremental Neural TTS</td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2020/pdfs/2103.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">21</a></td>
                            <td width="800">Lightweight LPCNet-based Neural Vocoder with Tensor Decomposition</td>
                            <td width="200"><a href="http://www.interspeech2020.org/index.php?m=content&c=index&a=show&catid=247&id=348">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">High quality lightweight and adaptable TTS using LPCNet</td>
                            <td width="200"><a href="../pdf/tts_paper/High quality lightweight and adaptable TTS using LPCNet.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">A Neural Vocoder with Hierarchical Generation of Amplitude and Phase Spectra for Statistical Parametric Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/A_Neural_Vocoder_with_Hierarchical_Generation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">RawNet: Fast End-to-End Neural Vocoder</td>
                            <td width="200"><a href="../pdf/tts_paper/RawNet Fast End-to-End Neural Vocoder.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet</td>
                            <td width="200"><a href="../pdf/tts_paper/A Real-Time Wideband Neural Vocoder at 1.6 kbs Using LPCNet.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</td>
                            <td width="800">Lpcnet improving neural speech synthesis through linear prediction</td>
                            <td width="200"><a href="../pdf/tts_paper/LPCNET: IMPROVING NEURAL SPEECH SYNTHESIS THROUGH LINEAR PREDICTION.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://people.xiph.org/~jm/demo/lpcnet/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/drowe67/LPCNet">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Waveglow</td>
                            <td width="200"><a href="../pdf/tts_paper/waveglow.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">melgan</td>
                            <td width="200"><a href="../pdf/tts_paper/MelGAN Generative Adversarial Networks for Conditional Waveform Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">AN INVESTIGATION OF SUBBAND WAVENET VOCODER COVERING ENTIRE AUDIBLE FREQUENCY RANGE WITH LIMITED ACOUSTIC FEATURES</td>
                            <td width="200"><a href="../pdf/tts_paper/AN INVESTIGATION OF SUBBAND WAVENET VOCODER COVERING ENTIRE AUDIBLE FREQUENCY RANGE WITH LIMITED ACOUSTIC FEATURES.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">A Comparison of Recent Neural Vocoders for Speech Signal Reconstruction</td>
                            <td width="200"><a href="https://pdfs.semanticscholar.org/093a/804dc251dbd68b190918e180707bd1f66e4b.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Natural TTS Synthesis by Conditioning Wavennet on MEL spectrogram predictions(tacotron2)</td>
                            <td width="200"><a href="../pdf/tts_paper/Natural_TTS_Synthesis by_Conditioning_Wavennet_on_MEL_spectrogram_predictions.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/NVIDIA/tacotron2">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Efficient Neural Audio Synthesis (WaveRNN)</td>
                            <td width="200"><a href="../pdf/tts_paper/Efficient Neural Audio Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Improving FFTNet vocoder with noise shaping and subband approaches</td>
                            <td width="200"><a href="../pdf/tts_paper/Improving FFTNet vocoder with noise shaping and subband approaches.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">FFTNET: A REAL-TIME SPEAKER-DEPENDENT NEURAL VOCODER</td>
                            <td width="200"><a href="../pdf/tts_paper/FFTNET: A REAL-TIME SPEAKER-DEPENDENT NEURAL VOCODER.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">SQUEEZEWAVE: EXTREMELY LIGHTWEIGHT VOCODERS FOR ON-DEVICE SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/SQUEEZEWAVE: EXTREMELY LIGHTWEIGHT VOCODERS FOR ON-DEVICE SPEECH SYNTHESIS.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/tianrengao/SqueezeWave">code</a>
                            </td>
                        </tr>
            </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Parallel WaveNet: Fast High-Fidelity Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Parallel_WaveNet-Fast_High-Fidelity_Speech_Synthesis.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2016 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Wavenet A Generative Model For Raw Audio</td>
                            <td width="200"><a href="../pdf/tts_paper/Wavenet_A_Generative_Model_For_Raw_Audio.pdf">pdf</a>&nbsp&nbsp
                                <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/ibab/tensorflow-wavenet">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Fast Wavenet Geneartion Algorithm</td>
                            <td width="200"><a href="../pdf/tts_paper/Fast_Wavenet_Geneartion_Algorithm.pdf">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-3">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Multispeaker & Multilingual</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Cross lingual Multispeaker Text to Speech under Limited Data Scenario</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 Cross lingual Multispeaker Text to Speech under Limited Data Scenario.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Efficient neural speech synthesis for low resource languages through multilingual modeling</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 Efficient neural speech synthesis for low resource languages through multilingual modeling.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">EndtoEnd Code Switching TTS with Cross Lingual Language Model</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 EndtoEnd Code Switching TTS with Cross Lingual Language Model.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">Generating Multilingual Voices Using Speaker Space Translation Based on Bilingual Speaker Data</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 Generating Multilingual Voices Using Speaker Space Translation Based on Bilingual Speaker Data.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</td>
                            <td width="800">One Model Many Languages  Meta learning for Multilingual Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 One Model Many Languages  Meta learning for Multilingual Text to Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</td>
                            <td width="800">SPEAKER ADAPTATION OF A MULTILINGUAL ACOUSTIC MODEL FOR CROSS-LANGUAGE SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 SPEAKER ADAPTATION OF A MULTILINGUAL ACOUSTIC MODEL FOR CROSS-LANGUAGE SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</td>
                            <td width="800">Multilingual speech synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Multilingual speech synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</td>
                            <td width="800">Domain-adversarial training of multi-speaker TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Domain adversarial training of multi speaker TTS .pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Focusing on Attention Prosody Transfer and Adaptative Optimization Strategy for Multi Speaker End to End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Focusing on Attention Prosody Transfer and Adaptative Optimization Strategy for Multi Speaker End to End Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">10</a></td>
                            <td width="800">Zero Shot Multi Speaker Text To Speech with State of the art Neural Speaker Embeddings</td>
                            <td width="200"><a href="../pdf/tts_paper/Zero Shot Multi Speaker Text To Speech with State of the art Neural Speaker Embeddings.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">11</a></td>
                            <td width="800">Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">12</a></td>
                            <td width="800">Multi-speaker Text-to-speech Synthesis Using Deep Gaussian Processes</td>
                            <td width="200"><a href="../pdf/tts_paper/Multi-speaker Text-to-speech Synthesis Using Deep Gaussian Processes.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">13</a></td>
                            <td width="800">Phonological Features for 0-shot Multilingual Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Phonological Features for 0-shot Multilingual Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">14</a></td>
                            <td width="800">Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis Using Discrete Speech Representation</td>
                            <td width="200"><a href="../pdf/tts_paper/Semi-supervised Learning for Multi-speaker Text-to-speech Synthesis Using Discrete Speech Representation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">15</a></td>
                            <td width="800">Towards Natural Bilingual and Code-Switched Speech Synthesis Based on Mix of Monolingual Recordings and Cross-Lingual Voice Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/Towards Natural Bilingual and Code-Switched Speech Synthesis Based on Mix of Monolingual Recordings and Cross-Lingual Voice Conversion.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">16</a></td>
                            <td width="800">USING IPA-BASED TACOTRON FOR DATA EFFICIENT CROSS-LINGUAL SPEAKER ADAPTATION AND PRONUNCIATION ENHANCEMENT</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.06392.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Cross lingual Multi speaker Texttospeech Synthesis for Voice Cloning without Using Parallel Corpus for Unseen Speakers</td>
                            <td width="200"><a href="../pdf/tts_paper/2019 Cross lingual Multi speaker Texttospeech Synthesis for Voice Cloning without Using Parallel Corpus for Unseen Speakers.pdf ">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Learning to Speak Fluently in a Foreign Language Multilingual Speech Synthesis and Cross Language Voice Cloning</td>
                            <td width="200"><a href="../pdf/tts_paper/2019 Learning to Speak Fluently in a Foreign Language Multilingual Speech Synthesis and Cross Language Voice Cloning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">个性化语音合成中说话人特征不同嵌入方式的研究</td>
                            <td width="200"><a href="../pdf/tts_paper/2019 个性化语音合成中说话人特征不同嵌入方式的研究.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Cross lingual Multispeaker Text To Speech Synthesis Using Neural Speaker Embedding</td>
                            <td width="200"><a href="../pdf/tts_paper/Cross lingual Multispeaker Text To Speech Synthesis Using Neural Speaker Embedding.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</td>
                            <td width="800">Automatic Multispeaker Voice Cloning</td>
                            <td width="200"><a href="../pdf/tts_paper/Automatic Multispeaker Voice Cloning.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</td>
                            <td width="800">Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://google.github.io/tacotron/publications/speaker_adaptation/">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</td>
                            <td width="800">Training Multi-Speaker Neural Text-to-Speech Systems using Speaker-Imbalanced Speech Corpora</td>
                            <td width="200"><a href="../pdf/tts_paper/Training Multi-Speaker Neural Text-to-Speech Systems using Speaker-Imbalanced Speech Corpora.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Speaker adaptation in DNN-based speech synthesis using d-vectors</td>
                            <td width="200"><a href="../pdf/tts_paper/Speaker adaptation in DNNbased speech synthesis using dvectors.pdf">pdf</a>
                            </td>
                        </tr>
          </table>
            <h3> 2016 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Speaker Representations for Speaker Adaptation in Multiple Speakers’BLSTM-RNN-based Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Speaker Representations for Speaker Adaptation in Multiple Speakers’BLSTM-RNN-based Speech Synthesis.pdf">pdf</a></td>
                        </tr>
          </table>
            <h3> 2015 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Multi-speaker modeling and speaker adaptation for dnn-based tts synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Multispeaker modeling and speaker adaptation for dnnbased tts synthesis.pdf">pdf</a>
                            </td>
                        </tr>
          </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-4">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Expressive TTS</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Whispered and Lombard Neural Speech Synthesis</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2101.05313.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Controllable Neural Prosody Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Controllable Neural Prosody Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">FULLY-HIERARCHICAL FINE-GRAINED PROSODY MODELING FOR INTERPRETABLE SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/FULLY-HIERARCHICAL FINE-GRAINED PROSODY MODELING FOR INTERPRETABLE SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Flowtron- an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Flowtron- an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Enhancing Speech Intelligibility in Text-To-Speech Synthesis using Speaking Style Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/Enhancing Speech Intelligibility in Text-To-Speech Synthesis using Speaking Style Conversion.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">Hierarchical Multi-Grained Generative Model for Expressive Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Hierarchical Multi-Grained Generative Model for Expressive Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">Controllable Emotion Transfer For End-to-End Speech Synthesis</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.08679.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">Fine-grained Emotion Strength Transfer, Control and Prediction for Emotional Speech Synthesis</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.08477.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">MULTI-REFERENCE NEURAL TTS STYLIZATION WITH ADVERSARIAL CYCLE CONSISTENCY</td>
                            <td width="200"><a href="../pdf/tts_paper/MULTI-REFERENCE NEURAL TTS STYLIZATION WITH ADVERSARIAL CYCLE CONSISTENCY.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Multi-reference Tacotron by Intercross Training for Style Disentangling, Transfer and Control in Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Multi-reference Tacotron by Intercross Training for Style Disentangling, Transfer and Control in Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">MELLOTRON- MULTISPEAKER EXPRESSIVE VOICE SYNTHESIS BY CONDITIONING ON RHYTHM, PITCH AND GLOBAL STYLE TOKENS</td>
                            <td width="200"><a href="../pdf/tts_paper/MELLOTRON- MULTISPEAKER EXPRESSIVE VOICE SYNTHESIS BY CONDITIONING ON RHYTHM, PITCH AND GLOBAL STYLE TOKENS.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">HIERARCHICAL GENERATIVE MODELING FOR CONTROLLABLE SPEECH SYNTHESIS.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/HIERARCHICAL GENERATIVE MODELING FOR CONTROLLABLE SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron</td>
                            <td width="200"><a href="../pdf/tts_paper/Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Style Tokens- Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Style Tokens- Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">PREDICTING EXPRESSIVE SPEAKING STYLE FROM TEXT IN END-TO-END SPEECH SYNTHESIS.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/PREDICTING EXPRESSIVE SPEAKING STYLE FROM TEXT IN END-TO-END SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-5">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Voice Conversion</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2021 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">EMOCAT: LANGUAGE-AGNOSTIC EMOTIONAL VOICE CONVERSION</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2101.05695.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data</td>
                            <td width="200"><a href="../pdf/tts_paper/Cotatron: Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">An Overview of Voice Conversion and its Challenges: From Statistical Modeling to Deep Learning</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2008.03648.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Converting Anyone’s Emotion- Towards Speaker-Independent Emotional Voice Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/Converting Anyone’s Emotion- Towards Speaker-Independent Emotional Voice Conversion.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">SEEN AND UNSEEN EMOTIONAL STYLE TRANSFER FOR VOICE CONVERSION WITH A NEW EMOTIONAL SPEECH DATASET</td>
                            <td width="200"><a href="../pdf/tts_paper/SEEN AND UNSEEN EMOTIONAL STYLE TRANSFER FOR VOICE CONVERSION WITH A NEW EMOTIONAL SPEECH DATASET.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</a></td>
                            <td width="800">ANY-TO-ONE SEQUENCE-TO-SEQUENCE VOICE CONVERSION USING SELF-SUPERVISED DISCRETE SPEECH REPRESENTATIONS</td>
                            <td width="200"><a href="../pdf/tts_paper/ANY-TO-ONE SEQUENCE-TO-SEQUENCE VOICE CONVERSION USING SELF-SUPERVISED DISCRETE SPEECH REPRESENTATIONS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">6</a></td>
                            <td width="800">GAZEV- GAN-Based Zero-Shot Voice Conversion over Non-parallel Speech Corpus</td>
                            <td width="200"><a href="../pdf/tts_paper/GAZEV- GAN-Based Zero-Shot Voice Conversion over Non-parallel Speech Corpus.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">7</a></td>
                            <td width="800">TOWARDS LOW-RESOURCE STARGAN VOICE CONVERSION USING WEIGHT ADAPTIVE INSTANCE NORMALIZATION</td>
                            <td width="200"><a href="../pdf/tts_paper/TOWARDS LOW-RESOURCE STARGAN VOICE CONVERSION USING WEIGHT ADAPTIVE INSTANCE NORMALIZATION.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">8</a></td>
                            <td width="800">CycleGAN-VC3- Examining and Improving CycleGAN-VCs for Mel-spectrogram Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/CycleGAN-VC3- Examining and Improving CycleGAN-VCs for Mel-spectrogram Conversion.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">9</a></td>
                            <td width="800">Accent and Speaker Disentanglement in Many-to-many Voice Conversion</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.08609.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">AUTOVC- Zero-Shot Voice Style Transfer with Only Autoencoder Loss</td>
                            <td width="200"><a href="../pdf/tts_paper/AUTOVC- Zero-Shot Voice Style Transfer with Only Autoencoder Loss.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">An Overview of Voice Conversion Systems</td>
                            <td width="200"><a href="../pdf/tts_paper/An Overview of Voice Conversion Systems.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/Unsupervised End-to-End Learning of Discrete Linguistic Units for Voice Conversion.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">An Overview of Voice Conversion Systems</td>
                            <td width="200"><a href="../pdf/tts_paper/An Overview of Voice Conversion Systems.pdf">pdf</a></td>
                        </tr>
            </table>


        </div>
    </div>
</section>
<section class="item card-box" id="row-6">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Sing Synthesis</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">HIFISINGER TOWARDS HIGH FIDELITY NEURAL SINGING VOICE SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/HIFISINGER TOWARDS HIGH FIDELITY NEURAL SINGING VOICE SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">ByteSing A Chinese Singing Voice Synthesis System Using Duration Allocated Encoder Decoder Acoustic Models and WaveRNN Vocoders</td>
                            <td width="200"><a href="../pdf/tts_paper/ByteSing A Chinese Singing Voice Synthesis System Using Duration Allocated Encoder Decoder Acoustic Models and WaveRNN Vocoders.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">DurIAN SC Duration Informed Attention Network based Singing Voice Conversion System</td>
                            <td width="200"><a href="../pdf/tts_paper/DurIAN SC Duration Informed Attention Network based Singing Voice Conversion System.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</td>
                            <td width="800">Jukebox A Generative Model for Music</td>
                            <td width="200"><a href="../pdf/tts_paper/Jukebox A Generative Model for Music.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">5</td>
                            <td width="800">XiaoiceSing- A High-Quality and Integrated Singing Voice Synthesis System</td>
                            <td width="200"><a href="../pdf/tts_paper/XiaoiceSing- A High-Quality and Integrated Singing Voice Synthesis System.pdf">pdf</a></td>
                        </tr>
                            <td width="150" align="center">6</td>
                            <td width="800">Speech-to-Singing Conversion based on Boundary Equilibrium GAN</td>
                            <td width="200"><a href="../pdf/tts_paper/Speech-to-Singing Conversion based on Boundary Equilibrium GAN.pdf">pdf</a></td>
                        </tr>
                        </tr>
                            <td width="150" align="center">7</td>
                            <td width="800">A Comprehensive Survey on Deep Music Generation: Multi-level Representations, Algorithms, Evaluations, and Future Directions</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2011.06801.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">MELLOTRON- MULTISPEAKER EXPRESSIVE VOICE SYNTHESIS BY CONDITIONING ON RHYTHM, PITCH AND GLOBAL STYLE TOKENS</td>
                            <td width="200"><a href="../pdf/tts_paper/MELLOTRON- MULTISPEAKER EXPRESSIVE VOICE SYNTHESIS BY CONDITIONING ON RHYTHM, PITCH AND GLOBAL STYLE TOKENS.pdf">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-7">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Talking Head</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">What comprises a good talking head video generation? A Survey and Benchmark</td>
                            <td width="200"><a href="../pdf/tts_paper/What comprises a good talking head video generation? A Survey and Benchmark.pdf">pdf</a>
                            &nbsp&nbsp<a href="https://github.com/lelechen63/talking-head-generation-survey">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">A Novel Face-tracking Mouth Controller and its Application to Interacting with Bioacoustic Models</td>
                            <td width="200"><a href="../pdf/tts_paper/A Novel Face-tracking Mouth Controller and its Application to Interacting with Bioacoustic Models.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">Large-scale multilingual audio visual dubbing</td>
                            <td width="200"><a href="../pdf/tts_paper/Large-scale multilingual audio visual dubbing.pdf">pdf</a>
                            </td>
                        </tr>
             </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">(talking head) Text-based Editing of Talking-head Video</td>
                            <td width="200"><a href="../pdf/tts_paper/Text-based Editing of Talking-head Video.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://www.ohadf.com/projects/text-based-editing/">vedio</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Talking Face Generation by Adversarially Disentangled Audio-Visual Representation</td>
                            <td width="200"><a href="../pdf/tts_paper/Talking Face Generation by Adversarially Disentangled Audio-Visual Representation.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/Hangz-nju-cuhk/Talking-Face-Generation-DAVS">code</a>
                                &nbsp&nbsp<a href="https://www.youtube.com/watch?v=-J2zANwdjcQ">demo</a>
                            </td>
                        </tr>
             </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-8">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Robust TTS</strong>
            </div>
            <!--获取内容列表-->

            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Noise Robust TTS for Low Resource Speakers using Pre-trained Model and Speech Enhancement</td>
                            <td width="200"><a href="../pdf/tts_paper/Noise Robust TTS for Low Resource Speakers using Pre-trained Model and Speech Enhancement.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</td>
                            <td width="800">Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training</td>
                            <td width="200"><a href="../pdf/tts_paper/Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Neural Text to Speech Adaptation from Low Quality Public Recordings</td>
                            <td width="200"><a href="../pdf/tts_paper/Neural Text to Speech Adaptation from Low Quality Public Recordings.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Disentangling Correlated Speaker and Noise for Speech Synthesis via Data Augmentation and Adversarial Factorization</td>
                            <td width="200"><a href="../pdf/tts_paper/32102.pdf">pdf</a></td>
                        </tr>
            </table>
        </div>
    </div>
</section>

</section>
<section class="item card-box" id="row-9">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Front End</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">A UNIFIED SEQUENCE-TO-SEQUENCE FRONT-END MODEL FOR MANDARIN TEXT-TO-SPEECH SYNTHESIS.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/A UNIFIED SEQUENCE-TO-SEQUENCE FRONT-END MODEL FOR MANDARIN TEXT-TO-SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">A HYBRID TEXT NORMALIZATION SYSTEM USING MULTI-HEAD SELF-ATTENTION FOR MANDARIN.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/A HYBRID TEXT NORMALIZATION SYSTEM USING MULTI-HEAD SELF-ATTENTION FOR MANDARIN.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">A Mask-based Model for Mandarin Chinese Polyphone Disambiguation</td>
                            <td width="200"><a href="../pdf/tts_paper/A Mask-based Model for Mandarin Chinese Polyphone Disambiguation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Unified Mandarin TTS Front-end Based on Distilled BERT Model</td>
                            <td width="200"><a href="https://arxiv.org/pdf/2012.15404.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">A Mandarin Prosodic Boundary Prediction Model Based on Multi Task Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/A Mandarin Prosodic Boundary Prediction Model Based on Multi Task Learning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Token Level Ensemble Distillation for Grapheme to Phoneme Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/Token Level Ensemble Distillation for Grapheme to Phoneme Conversion.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Pre trained Text Representations for Improving Front End Text Processing in Mandarin Text to Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Pre trained Text Representations for Improving Front End Text Processing in Mandarin Text to Speech Synthesis.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Mandarin Prosody Prediction Based on Attention Mechanism and Multi-model Ensemble</td>
                            <td width="200"><a href="../pdf/tts_paper/Mandarin Prosody Prediction Based on Attention Mechanism and Multimodel Ensemble.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2016 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach</td>
                            <td width="200"><a href="../pdf/tts_paper/Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2015 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES</td>
                            <td width="200"><a href="../pdf/tts_paper/AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES.pdf">pdf</a></td>
                        </tr>
            </table>
        </div>
    </div>
</section>

<section class="item card-box" id="row-10">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Alignment</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">LOCATION-RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG-FORM SPEECH SYNTHESIS</td>
                            <td width="200"><a href="https://arxiv.org/pdf/1910.10288.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Attentron- Few-Shot Text-to-Speech Utilizing Attention-Based Variable-Length Embedding</td>
                            <td width="200"><a href="../pdf/tts_paper/Attentron- Few-Shot Text-to-Speech Utilizing Attention-Based Variable-Length Embedding.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">3</a></td>
                            <td width="800">Peking Opera Synthesis via Duration Informed Attention Network</td>
                            <td width="200"><a href="../pdf/tts_paper/Peking Opera Synthesis via Duration Informed Attention Network.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">4</a></td>
                            <td width="800">Understanding Self-Attention of Self-Supervised Audio Transformers</td>
                            <td width="200"><a href="../pdf/tts_paper/Understanding Self-Attention of Self-Supervised Audio Transformers.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Initial investigation of an encoder-decoder end-to-end TTS framework using marginalization of monotonic hard latent alignments</td>
                            <td width="200"><a href="../pdf/tts_paper/Initial investigation of an encoder-decoder end-to-end TTS framework using marginalization of monotonic hard latent alignments.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Robust Sequence-to-Sequence Acoustic Modeling with Stepwise Monotonic Attention for Neural TTS </td>
                            <td width="200"><a href="https://arxiv.org/pdf/1906.00672.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">MONOTONIC CHUNKWISE ATTENTION</td>
                            <td width="200"><a href="../pdf/tts_paper/MONOTONIC CHUNKWISE ATTENTION.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">FORWARD ATTENTION IN SEQUENCE-TO-SEQUENCE ACOUSTIC MODELING FOR SPEECH SYNTHESIS.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/FORWARD ATTENTION IN SEQUENCE-TO-SEQUENCE ACOUSTIC MODELING FOR SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2017 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</a></td>
                            <td width="800">Online and Linear-Time Attention by Enforcing Monotonic Alignments</td>
                            <td width="200"><a href="../pdf/tts_paper/Online and Linear-Time Attention by Enforcing Monotonic Alignments.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</a></td>
                            <td width="800">Attention Is All You Need</td>
                            <td width="200"><a href="../pdf/tts_paper/Attention Is All You Need">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-11">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Dual Learning</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">LRSpeech- Extremely Low-Resource Speech Synthesis and Recognition</td>
                            <td width="200"><a href="../pdf/tts_paper/LRSpeech- Extremely Low-Resource Speech Synthesis and Recognition.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Almost Unsupervised Text to Speech and Automatic Speech Recognition</td>
                            <td width="200"><a href="../pdf/tts_paper/Almost Unsupervised Text to Speech and Automatic Speech Recognition.pdf">pdf</a>
                            </td>
                        </tr>
             </table>
            <h3> 2018 </h3>
            <table width="1150" border="1">
                        <tr>
                            <td width="150" align="center">1</td>
                            <td width="800">Machine Speech Chain with One-shot Speaker Adaptation</td>
                            <td width="200"><a href="../pdf/tts_paper/Machine Speech Chain with One-shot Speaker Adaptation.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="150" align="center">2</td>
                            <td width="800">Listening while Speaking- Speech Chain by Deep Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/Listening while Speaking- Speech Chain by Deep Learning.pdf">pdf</a>
                            </td>
                        </tr>
             </table>
        </div>
    </div>
</section>

<!--页脚-->
<footer class="footer">
    <div class="container">
        <div class="rwo">
            <div class="col-md-12">
                <p>
                    本站内容源自互联网，如有内容侵犯了你的权益，请联系删除相关内容，联系邮箱：yongqiangli@alumni.hust.edu.cn
                </p>
                <!--代码源自小呆导航的开源代码，遵循MIT协议，此处保留源代码的声明-->
                <p>
                    Copyright © 2018-2020 li yongqiang All Rights Reserved
                </p>
            </div>
        </div>
    </div>
</footer>
</div>
<!--内容区域-->
</div>
<div id="get-top" title="回到顶部">
    <i class="icon icon-arrow-up"></i>
</div>

<!-- jQuery (ZUI中的Javascript组件依赖于jQuery) -->
<script src="http://code.jquery.com/jquery-1.11.0.min.js"></script>

<script>
    window.onscroll = function(){
//回到顶部
var sllTop = document.documentElement.scrollTop||document.body.scrollTop;
if(sllTop>240){
  $('#get-top').css('display','block')
}else{
  $('#get-top').css('display','none')
}
}
$('#get-top').click(function(){ 
  $('body,html').animate({
    scrollTop: 0
  }, 800);//点击回到顶部按钮，数字越小越快
})
//判断用户使用的设备
var deviceVal  = browserRedirect();
function browserRedirect() {
  var sUserAgent = navigator.userAgent.toLowerCase();
  var bIsIpad = sUserAgent.match(/ipad/i) == "ipad";
  var bIsIphoneOs = sUserAgent.match(/iphone os/i) == "iphone os";
  var bIsMidp = sUserAgent.match(/midp/i) == "midp";
  var bIsUc7 = sUserAgent.match(/rv:1.2.3.4/i) == "rv:1.2.3.4";
  var bIsUc = sUserAgent.match(/ucweb/i) == "ucweb";
  var bIsAndroid = sUserAgent.match(/android/i) == "android";
  var bIsCE = sUserAgent.match(/windows ce/i) == "windows ce";
  var bIsWM = sUserAgent.match(/windows mobile/i) == "windows mobile";
  if (bIsIpad || bIsIphoneOs || bIsMidp || bIsUc7 || bIsUc || bIsAndroid || bIsCE || bIsWM) {
    return 'phone';
} else {
    return 'pc';
}
}
$('.nav-btn').on('click', function () {
    $('.nav').toggleClass('showNav');
    $(this).toggleClass('animated2');
});

</script>
</div>
</body>
</html>
