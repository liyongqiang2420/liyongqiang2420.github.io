<!DOCTYPE html>
<html lang="zh-cn">
<head>
    <!--头部信息-->
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <!--title keywords description 请改为自己的-->
    <title>低调奋进</title>

    <!--网站favicon可以没有或者改为自己的-->
    <!--<link rel="shortcut icon" type="image/x-icon" href="http://www.bituplink.com/wp-content/uploads/favicon.png"/>-->

    <!--CSS 若不需要变动样式不用改-->
    <link href="plugin/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/zui/1.8.1/css/zui.min.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" type="text/css" href="../css/common.css" />
    <link href="../img/logo.ico" rel="shortcut icon" />
    <script src="plugin/jquery.min.js"></script>
    <script src="plugin/bootstrap/js/bootstrap.min.js"></script>
</head>
<body id="nav_body">
<!--[if lt IE 10]>
<div class="alert alert-danger">
    您正在使用 
    <strong>过时的</strong> 浏览器. 请更换一个更好的浏览器来提升用户体验.
</div>
<![endif]--><!--头部导航条-->
<div id="content">
    <div class="w_header">
      <div class="container">
        <div class="w_header_top">
          <a href="#" class="w_logo"></a>
          <span class="w_header_nav">
              <ul>
                <li><a href="../index.html">首页</a></li>
                <li><a href="speech.html" class="active">语音</a></li>
                <li><a href="nlp.html">自然语言</a></li>
                <li><a href="ml.html">机器学习</a></li>
                <li><a href="pro.html">编程</a></li>
                <li><a href="moodList.html">修养</a></li>
                <li><a href="tools.html">工具</a></li>
                <li><a href="comment.html">留言</a></li>
                <li><a href="about.html">关于</a></li>
            </ul>
        </span>
    </div>
</div>
</div>

<!--左侧目录，导航跳转-->
<div class="left-bar">
    <div class="header">
        <h2>目录</h2>
    </div>
    <div class="menu" id="menu">
        <ul class="scrollcontent">
            <!--左侧目录，按照需要修改和添加，参考已有的修改名称和href-->
            <li><a href="#row-1">通用TTS</a></li>
            <li><a href="#row-2">声码器</a></li>
            <li><a href="#row-3">个性化:多人多语言</a></li>
            <li><a href="#row-4">情感和声音转换</a></li>
            <li><a href="#row-5">音乐合成</a></li>
            <li><a href="#row-6">虚拟主播</a></li>
            <li><a href="#row-7">Robust TTS</a></li>
            <li><a href="#row-8">multiband</a></li>
            <li><a href="#row-9">前端</a></li>
        </ul>
    </div>
</div>
<!--内容-->
<div class="main">
    <div class="container content-box">
        <!--导航分类范例1，请根据自己的需求进行修改-->
        <section class="item card-box" id="row-1">
            <div class="container-fluid">
                <div class="row">
                    <div class="item-tit">
                        <strong>通用TTS</strong>
                    </div>
                    <!--获取内容列表-->

                    <h3> 2020 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">2020</a></td>
                            <td width="50" align="center">icassp</td>
                            <td width="800">icassp 2020 speech synthesis session</td>
                            <td width="200"><a href="https://2020.ieeeicassp-virtual.org/session/machine-learning-speech-synthesis-i">session1</a>
                                &nbsp&nbsp<a href="https://2020.ieeeicassp-virtual.org/session/speech-synthesis-and-voice-conversion-i">session2</a>
                                &nbsp&nbsp<a href="https://2020.ieeeicassp-virtual.org/session/speech-synthesis-and-voice-conversion-ii">session3</a>
                            </td>
                        </tr> 
                        <tr>
                            <td width="50" align="center">speechresearch</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">speech research</td>
                            <td width="200"><a href="https://speechresearch.github.io/">web</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">AI research</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">AI research</td>
                            <td width="200"><a href="https://www.yanxishe.com/">web</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">ccf~</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">ccf语音对话与听觉前沿研讨会</td>
                            <td width="200"><a href="https://www.bilibili.com/video/BV1MV411k7iJ?from=search&seid=10382597287268936144">vedio</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">language processing</a></td>
                            <td width="50" align="center">course</td>
                            <td width="800">李宏毅</td>
                            <td width="200"><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses_DLHLP20.html">course</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">speech synthesis</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">李宏毅</td>
                            <td width="200"><a href="https://www.youtube.com/watch?v=DMxKeHW8KdM&feature=youtu.be">vedio</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2017~</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">tacotron</td>
                            <td width="200"><a href="https://google.github.io/tacotron/index.html">paper</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">INTERACTIVE TEXT-TO-SPEECH VIA SEMI-SUPERVISED STYLE TRANSFER LEARNING</td>
                            <td width="200"><a href="../pdf/tts_paper/INTERACTIVE TEXT-TO-SPEECH VIA SEMI-SUPERVISED STYLE TRANSFER LEARNING.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</td>
                            <td width="50" align="center">B</td>
                            <td width="800">SQUEEZEWAVE EXTREMELY LIGHTWEIGHT VOCODERS FOR ON DEVICE SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/SQUEEZEWAVE EXTREMELY LIGHTWEIGHT VOCODERS FOR ON DEVICE SPEECH SYNTHESIS.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://tianrengao.github.io/SqueezeWaveDemo/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/tianrengao/SqueezeWave">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">LOCATION RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG FORM SPEECH SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/LOCATION RELATIVE ATTENTION MECHANISMS FOR ROBUST LONG FORM SPEECH SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</td>
                            <td width="50" align="center">B</td>
                            <td width="800">End to End Adversarial Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/End to End Adversarial Text to Speech.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://deepmind.com/research/publications/End-to-End-Adversarial-Text-to-Speech">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">7</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">FastSpeech 2 Fast and High Quality End to End Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/FastSpeech 2 Fast and High Quality End to End Text to Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">10</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Deep Representation Learning in Speech Processing Challenges Recent Advances and Future Trends</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep Representation Learning in Speech Processing Challenges Recent Advances and Future Trends.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2019 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">2019</td>
                            <td width="50" align="center">isca</td>
                            <td width="800"> isca 2019 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2019/">papers</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">High quality, lightweight and adaptable TTS using LPCNet</td>
                            <td width="200"><a href="../pdf/tts_paper/high_quality_lightweight_and_adaptable_tts_using_lpcnet.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Deep Text-to-Speech System with Seq2Seq Model</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep_Text-to-Speech_System_with_Seq2Seq_Model.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</td>
                            <td width="50" align="center">B</td>
                            <td width="800">FastSpeech: Fast, Robust and Controllable Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/FastSpeech_Fast_Robust_and_Controllable_Text_to_Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</td>
                            <td width="50" align="center">B</td>
                            <td width="800">A Neural Vocoder with Hierarchical Generation of Amplitude and Phase Spectra for Statistical Parametric Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/A_Neural_Vocoder_with_Hierarchical_Generation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">5</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Neural Speech Synthesis with Transformer Network</td>
                            <td width="200"><a href="../pdf/tts_paper/Neural_Speech_Synthesis_with_Transformer_Network.pdf">pdf</a>
                                &nbsp&nbsp<a href="../pdf/tts_paper/tts transformer .pptx">ppt</a>
                                &nbsp&nbsp<a href="https://neuraltts.github.io/transformertts/">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">6</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Parallel Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/Parallel Neural Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">7</td>
                            <td width="50" align="center">B</td>
                            <td width="800">RawNet: Fast End-to-End Neural Vocoder</td>
                            <td width="200"><a href="../pdf/tts_paper/RawNet Fast End-to-End Neural Vocoder.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">8</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Exploiting Syntactic Features in a Parsed Tree to Improve End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">9</td>
                            <td width="50" align="center">O</td>
                            <td width="800">LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/libriTTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">10</td>
                            <td width="50" align="center">B</td>
                            <td width="800">A Real-Time Wideband Neural Vocoder at 1.6 kb/s Using LPCNet</td>
                            <td width="200"><a href="../pdf/tts_paper/A Real-Time Wideband Neural Vocoder at 1.6 kbs Using LPCNet.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">11</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Lpcnet improving neural speech synthesis through linear prediction</td>
                            <td width="200"><a href="../pdf/tts_paper/LPCNET: IMPROVING NEURAL SPEECH SYNTHESIS THROUGH LINEAR PREDICTION.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://people.xiph.org/~jm/demo/lpcnet/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/drowe67/LPCNet">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">12</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Forward-Backward Decoding for Regularizing End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Forward-Backward Decoding for Regularizing End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">13</td>
                            <td width="50" align="center">O</td>
                            <td width="800">(talking head) Text-based Editing of Talking-head Video</td>
                            <td width="200"><a href="../pdf/tts_paper/Text-based Editing of Talking-head Video.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://www.ohadf.com/projects/text-based-editing/">vedio</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">14</td>
                            <td width="50" align="center">F</td>
                            <td width="800">Self-attention Based Prosodic Boundary Prediction for Chinese Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Self-attention Based Prosodic Boundary Prediction for Chinese Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">15</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Guide to Speech Synthesis with Deep Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/Guide to Speech Synthesis with Deep Learning.pdf">ppt</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">16</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">tts tutorial part1 part2</td>
                            <td width="200"><a href="../pdf/tts_paper/tts tutorial part1.pdf">ppt1</a>
                                &nbsp&nbsp<a href="../pdf/tts_paper/tts_tutorial part2.pdf">ppt2</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">17</a></td>
                            <td width="50" align="center">M</td>
                            <td width="800">learning to speak fluently in a foreign language multilingual speech synthesis and cross language voice cloning</td>
                            <td width="200"><a href="../pdf/tts_paper/learning to speak fluently in a foreign language multilingual speech synthesis and cross language voice cloning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">18</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">maximizing mutual infotmation for tacotron</td>
                            <td width="200"><a href="../pdf/tts_paper/MAXIMIZING MUTUAL INFORMATION FOR TACOTRON.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">19</a></td>
                            <td width="50" align="center">F</td>
                            <td width="800">Token Level Ensemble Distillation for Grapheme to Phoneme Conversion</td>
                            <td width="200"><a href="../pdf/tts_paper/Token Level Ensemble Distillation for Grapheme to Phoneme Conversion.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">20</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Cross lingual Multispeaker Text To Speech Synthesis Using Neural Speaker Embedding</td>
                            <td width="200"><a href="../pdf/tts_paper/Cross lingual Multispeaker Text To Speech Synthesis Using Neural Speaker Embedding.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">21</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Waveglow</td>
                            <td width="200"><a href="../pdf/tts_paper/waveglow.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">22</td>
                            <td width="50" align="center">B</td>
                            <td width="800">durlan</td>
                            <td width="200"><a href="../pdf/tts_paper/DURIAN DURATION INFORMED ATTENTION NETWORK FOR MULTIMODAL SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">23</td>
                            <td width="50" align="center">O</td>
                            <td width="800">Talking Face Generation by Adversarially Disentangled Audio-Visual Representation</td>
                            <td width="200"><a href="../pdf/tts_paper/Talking Face Generation by Adversarially Disentangled Audio-Visual Representation.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/Hangz-nju-cuhk/Talking-Face-Generation-DAVS">code</a>
                                &nbsp&nbsp<a href="https://www.youtube.com/watch?v=-J2zANwdjcQ">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">24</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Automatic Multispeaker Voice Cloning</td>
                            <td width="200"><a href="../pdf/tts_paper/Automatic Multispeaker Voice Cloning.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/CorentinJ/Real-Time-Voice-Cloning">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">25</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://google.github.io/tacotron/publications/speaker_adaptation/">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">26</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://google.github.io/tacotron/publications/speaker_adaptation/">demo</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">27</td>
                            <td width="50" align="center">B</td>
                            <td width="800">High quality lightweight and adaptable TTS using LPCNet</td>
                            <td width="200"><a href="../pdf/tts_paper/High quality lightweight and adaptable TTS using LPCNet.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">28</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Cross lingual Multispeaker TextToSpeech Synthesis Using Neural Speaker Embedding</td>
                            <td width="200"><a href="../pdf/tts_paper/Cross lingual Multispeaker TextToSpeech Synthesis Using Neural Speaker Embedding.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>
                    <h3> 2018 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">2018</td>
                            <td width="50" align="center">isca</td>
                            <td width="800"> isca 2018 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2018/">papers</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Natural TTS Synthesis by Conditioning Wavennet on MEL spectrogram predictions(tacotron2)</td>
                            <td width="200"><a href="../pdf/tts_paper/Natural_TTS_Synthesis by_Conditioning_Wavennet_on_MEL_spectrogram_predictions.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://github.com/NVIDIA/tacotron2">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Deep voice 3: Scaling text-to-speech with convolutional sequence learning</td>
                            <td width="200"><a href="../pdf/tts_paper/deep_voice3.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">ClariNet Parallel Wave Generation in End-to-End Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/ClariNet Parallel Wave Generation in End-to-End Text-to-Speech.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Efficient Neural Audio Synthesis (WaveRNN)</td>
                            <td width="200"><a href="../pdf/tts_paper/Efficient Neural Audio Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">5</a></td>
                            <td width="50" align="center">F</td>
                            <td width="800">Mandarin Prosody Prediction Based on Attention Mechanism and Multi-model Ensemble</td>
                            <td width="200"><a href="../pdf/tts_paper/Mandarin Prosody Prediction Based on Attention Mechanism and Multimodel Ensemble.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">6</a></td>
                            <td width="50" align="center">A</td>
                            <td width="800">Linear Networks Based Speaker Adaptation For Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Linear Networks Based Speaker Adaptation For Speech Synthesis.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>    
                    <h3> 2017 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">2017</td>
                            <td width="50" align="center">isca</td>
                            <td width="800"> isca 2017 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2017/">papers</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Tacotron: Towards End-to-End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/tacotron.pdf">pdf</a>
                                &nbsp&nbsp<a href="https://google.github.io/tacotron/index.html">page</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Parallel WaveNet: Fast High-Fidelity Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Parallel_WaveNet-Fast_High-Fidelity_Speech_Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Char2Wav: End-to-End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Char2Wav-End-to-End_Speech_Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Deep Voice: Real-time Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/Deep_Voice-Real-time_Neural_Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">5</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Deep Voice 2: Multi-Speaker Neural Text-to-Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/DeepVoice2-Multi-Speaker_Neural_Text-to-Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">6</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">VoiceLoop voice fitting and synthesis via a phonological loop</td>
                            <td width="200"><a href="../pdf/tts_paper/VOICELOOP- VOICE FITTING AND SYNTHESIS VIA A PHONOLOGICAL LOOP.pdf">pdf</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">7</a></td>
                            <td width="50" align="center">O</td>
                            <td width="800">Attention Is All You Need</td>
                            <td width="200"><a href="../pdf/tts_paper/Attention Is All You Need.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">8</a></td>
                            <td width="50" align="center">A</td>
                            <td width="800">Speaker adaptation in DNN-based speech synthesis using d-vectors</td>
                            <td width="200"><a href="../pdf/tts_paper/Speaker adaptation in DNNbased speech synthesis using dvectors.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>
                    <h3> 2016 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">2016</td>
                            <td width="50" align="center">isca</td>
                            <td width="800"> isca 2016 speech </td>
                            <td width="200"><a href="https://www.isca-speech.org/archive/Interspeech_2016/">papers</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Wavenet A Generative Model For Raw Audio</td>
                            <td width="200"><a href="../pdf/tts_paper/Wavenet_A_Generative_Model_For_Raw_Audio.pdf">pdf</a>&nbsp&nbsp
                                <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">demo</a>
                                &nbsp&nbsp<a href="https://github.com/ibab/tensorflow-wavenet">code</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Fast Wavenet Geneartion Algorithm</td>
                            <td width="200"><a href="../pdf/tts_paper/Fast_Wavenet_Geneartion_Algorithm.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Fast, Compact, and High Quality LSTM-RNN Based Statistical Parametric Speech Synthesizers for Mobile Devices</td>
                            <td width="200"><a href="../pdf/tts_paper/Fast_Compact_and_High_Quality_LSTM-RNN_Based_Statistical_Parametric.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Merlin: An Open Source Neural Network Speech Synthesis System</td>
                            <td width="200"><a href="../pdf/tts_paper/Merlin_An_Open_Source_Neural_Network_Speech_Synthesis_System.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">5</a></td>
                            <td width="50" align="center">F</td>
                            <td width="800">Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach</td>
                            <td width="200"><a href="../pdf/tts_paper/Improving Prosodic Boundaries Prediction for Mandarin Speech Synthesis by Using Enhanced Embedding Feature and Model Fusion Approach.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">6</a></td>
                            <td width="50" align="center">A</td>
                            <td width="800">Speaker Representations for Speaker Adaptation in Multiple Speakers’BLSTM-RNN-based Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Speaker Representations for Speaker Adaptation in Multiple Speakers’BLSTM-RNN-based Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                    </table>
                    <h3> 2015 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Acoustic modeling instatistical parametric speechsynthesis-from HMM to LSTM-RNN</td>
                            <td width="200"><a href="../pdf/tts_paper/Acoustic_modeling_instatistical_parametric_speechsynthesis-from_HMM_to_LSTM-RNN.pdf">pdf</a>
                                &nbsp&nbsp<a href="../pdf/tts_paper/Statistical Parametric Speech SynthesisFromHMMtoLSTMRNN_ppt.pdf">ppt</a>
                            </td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Effective Approaches to Attention-based Neural Machine Translation</td>
                            <td width="200"><a href="../pdf/tts_paper/Effective Approaches to Attention-based Neural Machine Translation.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">htkbook-3.5</td>
                            <td width="200"><a href="../pdf/tts_paper/htkbook-3.5.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</a></td>
                            <td width="50" align="center">F</td>
                            <td width="800">AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES</td>
                            <td width="200"><a href="../pdf/tts_paper/AUTOMATIC PROSODY PREDICTION FOR CHINESE SPEECH SYNTHESIS USING BLSTM-RNN AND EMBEDDING FEATURES.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">5</a></td>
                            <td width="50" align="center">A</td>
                            <td width="800">A study of speaker adaptation for DNN-based speech synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/A study of speaker adaptation for DNN-based speech synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">6</a></td>
                            <td width="50" align="center">A</td>
                            <td width="800">Multi-speaker modeling and speaker adaptation for dnn-based tts synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Multispeaker modeling and speaker adaptation for dnnbased tts synthesis.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>
                    <h3> 2014 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">TTS Synthesis with Bidirectional LSTM based Recurrent Neural Networks </td>
                            <td width="200"><a href="../pdf/tts_paper/TTS_Synthesis_with_Bidirectional_LSTM_based_Recurrent_Neural_Networks.pdf">pdf</a>
                            </td>
                        </tr>
                    </table>
                    <h3> 2013 </h3>
                    <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Statical parameteric speech synthesis Using deep neural networks </td>
                            <td width="200"><a href="../pdf/tts_paper/Statical parameteric speech synthesis Using deep neural networks.pdf">pdf</a></td>
                        </tr>
                    </table>
                </div>
            </div>
        </section>
<section class="item card-box" id="row-2">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>声码器</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">multiband melgan</td>
                            <td width="200"><a href="../pdf/tts_paper/multiband melgan.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">FeatherWave An efficient high fidelity neural vocoder with multiband linear prediction</td>
                            <td width="200"><a href="../pdf/tts_paper/FeatherWave An efficient high fidelity neural vocoder with multiband linear prediction.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">High quality lightweight and adaptable TTS using LPCNet</td>
                            <td width="200"><a href="../pdf/tts_paper/High quality lightweight and adaptable TTS using LPCNet.pdf">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-3">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>个性化:多人多语言</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Cross lingual Multispeaker Text to Speech under Limited Data Scenario</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 Cross lingual Multispeaker Text to Speech under Limited Data Scenario.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Efficient neural speech synthesis for low resource languages through multilingual modeling</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 Efficient neural speech synthesis for low resource languages through multilingual modeling.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</td>
                            <td width="50" align="center">B</td>
                            <td width="800">EndtoEnd Code Switching TTS with Cross Lingual Language Model</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 EndtoEnd Code Switching TTS with Cross Lingual Language Model.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">4</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Generating Multilingual Voices Using Speaker Space Translation Based on Bilingual Speaker Data</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 Generating Multilingual Voices Using Speaker Space Translation Based on Bilingual Speaker Data.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">5</td>
                            <td width="50" align="center">B</td>
                            <td width="800">One Model Many Languages  Meta learning for Multilingual Text to Speech</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 One Model Many Languages  Meta learning for Multilingual Text to Speech.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">6</td>
                            <td width="50" align="center">B</td>
                            <td width="800">SPEAKER ADAPTATION OF A MULTILINGUAL ACOUSTIC MODEL FOR CROSS-LANGUAGE SYNTHESIS</td>
                            <td width="200"><a href="../pdf/tts_paper/2020 SPEAKER ADAPTATION OF A MULTILINGUAL ACOUSTIC MODEL FOR CROSS-LANGUAGE SYNTHESIS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">7</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Multilingual speech synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Multilingual speech synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">8</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Domain-adversarial training of multi-speaker TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Domain adversarial training of multi speaker TTS .pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">9</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Focusing on Attention Prosody Transfer and Adaptative Optimization Strategy for Multi Speaker End to End Speech Synthesis</td>
                            <td width="200"><a href="../pdf/tts_paper/Focusing on Attention Prosody Transfer and Adaptative Optimization Strategy for Multi Speaker End to End Speech Synthesis.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">10</a></td>
                            <td width="50" align="center">B</td>
                            <td width="800">Zero Shot Multi Speaker Text To Speech with State of the art Neural Speaker Embeddings</td>
                            <td width="200"><a href="../pdf/tts_paper/Zero Shot Multi Speaker Text To Speech with State of the art Neural Speaker Embeddings.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Cross lingual Multi speaker Texttospeech Synthesis for Voice Cloning without Using Parallel Corpus for Unseen Speakers</td>
                            <td width="200"><a href="../pdf/tts_paper/2019 Cross lingual Multi speaker Texttospeech Synthesis for Voice Cloning without Using Parallel Corpus for Unseen Speakers.pdf ">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Learning to Speak Fluently in a Foreign Language Multilingual Speech Synthesis and Cross Language Voice Cloning</td>
                            <td width="200"><a href="../pdf/tts_paper/2019 Learning to Speak Fluently in a Foreign Language Multilingual Speech Synthesis and Cross Language Voice Cloning.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">3</td>
                            <td width="50" align="center">B</td>
                            <td width="800">个性化语音合成中说话人特征不同嵌入方式的研究</td>
                            <td width="200"><a href="../pdf/tts_paper/2019 个性化语音合成中说话人特征不同嵌入方式的研究.pdf">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-4">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>情感和声音转换</strong>
            </div>
            <!--获取内容列表-->

        </div>
    </div>
</section>
<section class="item card-box" id="row-5">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>音乐合成</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">HIFISINGER TOWARDS HIGH FIDELITY NEURAL SINGING VOICE SYNTHESIS.pdf</td>
                            <td width="200"><a href="../pdf/tts_paper/HIFISINGER TOWARDS HIGH FIDELITY NEURAL SINGING VOICE SYNTHESIS.pdf">pdf</a></td>
                        </tr>
            </table>

        </div>
    </div>
</section>
<section class="item card-box" id="row-6">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>虚拟主播</strong>
            </div>
            <!--获取内容列表-->

        </div>
    </div>
</section>
<section class="item card-box" id="row-7">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Robust TTS</strong>
            </div>
            <!--获取内容列表-->

            <h3> 2020 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS</td>
                            <td width="200"><a href="../pdf/tts_paper/Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Noise Robust TTS for Low Resource Speakers using Pre-trained Model and Speech Enhancement</td>
                            <td width="200"><a href="../pdf/tts_paper/Noise Robust TTS for Low Resource Speakers using Pre-trained Model and Speech Enhancement.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training</td>
                            <td width="200"><a href="../pdf/tts_paper/Data Efficient Voice Cloning from Noisy Samples with Domain Adversarial Training.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2019 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Neural Text to Speech Adaptation from Low Quality Public Recordings</td>
                            <td width="200"><a href="../pdf/tts_paper/Neural Text to Speech Adaptation from Low Quality Public Recordings.pdf">pdf</a></td>
                        </tr>
            </table>
            <h3> 2018 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">Disentangling Correlated Speaker and Noise for Speech Synthesis via Data Augmentation and Adversarial Factorization</td>
                            <td width="200"><a href="../pdf/tts_paper/Disentangling Correlated Speaker and Noise for Speech Synthesis via Data Augmentation and Adversarial Factorization.pdf">pdf</a></td>
                        </tr>
            </table>
        </div>
    </div>
</section>

</section>
<section class="item card-box" id="row-8">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>Multiband</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2020 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">multiband melgan</td>
                            <td width="200"><a href="../pdf/tts_paper/multiband melgan.pdf">pdf</a></td>
                        </tr>
                        <tr>
                            <td width="50" align="center">2</td>
                            <td width="50" align="center">B</td>
                            <td width="800">FeatherWave An efficient high fidelity neural vocoder with multiband linear prediction</td>
                            <td width="200"><a href="../pdf/tts_paper/FeatherWave An efficient high fidelity neural vocoder with multiband linear prediction.pdf">pdf</a></td>
                        </tr>
            </table>
        </div>
    </div>
</section>
<section class="item card-box" id="row-9">
    <div class="container-fluid">
        <div class="row">
            <div class="item-tit">
                <strong>前端</strong>
            </div>
            <!--获取内容列表-->
            <h3> 2019 </h3>
            <table width="1100" border="1">
                        <tr>
                            <td width="50" align="center">1</td>
                            <td width="50" align="center">B</td>
                            <td width="800">A Mandarin Prosodic Boundary Prediction Model Based on Multi Task Learning</td>
                            <td width="200"><a href="../pdf/tts_paper/A Mandarin Prosodic Boundary Prediction Model Based on Multi Task Learning.pdf">pdf</a></td>
                        </tr>
            </table>
        </div>
    </div>
</section>


<!--页脚-->
<footer class="footer">
    <div class="container">
        <div class="rwo">
            <div class="col-md-12">
                <p>
                    本站内容源自互联网，如有内容侵犯了你的权益，请联系删除相关内容，联系邮箱：yongqiangli@alumni.hust.edu.cn
                </p>
                <!--代码源自小呆导航的开源代码，遵循MIT协议，此处保留源代码的声明-->
                <p>
                    Copyright © 2018-2020 li yongqiang All Rights Reserved
                </p>
            </div>
        </div>
    </div>
</footer>
</div>
<!--内容区域-->
</div>
<div id="get-top" title="回到顶部">
    <i class="icon icon-arrow-up"></i>
</div>

<!-- jQuery (ZUI中的Javascript组件依赖于jQuery) -->
<script src="http://code.jquery.com/jquery-1.11.0.min.js"></script>

<script>
    window.onscroll = function(){
//回到顶部
var sllTop = document.documentElement.scrollTop||document.body.scrollTop;
if(sllTop>240){
  $('#get-top').css('display','block')
}else{
  $('#get-top').css('display','none')
}
}
$('#get-top').click(function(){ 
  $('body,html').animate({
    scrollTop: 0
  }, 800);//点击回到顶部按钮，数字越小越快
})
//判断用户使用的设备
var deviceVal  = browserRedirect();
function browserRedirect() {
  var sUserAgent = navigator.userAgent.toLowerCase();
  var bIsIpad = sUserAgent.match(/ipad/i) == "ipad";
  var bIsIphoneOs = sUserAgent.match(/iphone os/i) == "iphone os";
  var bIsMidp = sUserAgent.match(/midp/i) == "midp";
  var bIsUc7 = sUserAgent.match(/rv:1.2.3.4/i) == "rv:1.2.3.4";
  var bIsUc = sUserAgent.match(/ucweb/i) == "ucweb";
  var bIsAndroid = sUserAgent.match(/android/i) == "android";
  var bIsCE = sUserAgent.match(/windows ce/i) == "windows ce";
  var bIsWM = sUserAgent.match(/windows mobile/i) == "windows mobile";
  if (bIsIpad || bIsIphoneOs || bIsMidp || bIsUc7 || bIsUc || bIsAndroid || bIsCE || bIsWM) {
    return 'phone';
} else {
    return 'pc';
}
}
$('.nav-btn').on('click', function () {
    $('.nav').toggleClass('showNav');
    $(this).toggleClass('animated2');
});

</script>
</div>
</body>
</html>
